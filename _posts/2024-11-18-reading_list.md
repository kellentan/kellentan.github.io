---
title: 'Research Paper Reading List'
date: 2024-11-18
permalink: /posts/2024-11-16/research-paper-reading-list/
tags:
  - PhD
  - NLP
mathjax: true
---

Just a collection of potentially interesting papers that are on my reading list...

General Papers
======
1. Charlie Snell, Dan Klein, Ruiqi Zhong, [Learning by Distilling Context](https://arxiv.org/abs/2209.15189)
2. Alycia Lee, Brando Miranda, Sudharsan Sundar, Allison Casasola, Sanmi Koyejo, [Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data](https://openreview.net/forum?id=tgkWxsOapD)
3. Valeriia Cherepanova, James Zou, [Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs](https://openreview.net/forum?id=traR5SsqUt)
4. Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Lingpeng Kong, Qi Liu, Tianyu Liu, Zhifang Sui, [Large Language Models are not Fair Evaluators](https://aclanthology.org/2024.acl-long.511/)
5. Junmo Kang, Hongyin Luo, Yada Zhu, Jacob Hansen, James Glass, David Cox, Alan Ritter, Rogerio Feris, Leonid Karlinsky, [Self-Specialization: Uncovering Latent Expertise within Large Language Models](https://aclanthology.org/2024.findings-acl.157/)
6. Shuqian Sheng, Yi Xu, Luoyi Fu, Jiaxin Ding, Lei Zhou, Xinbing Wang, Chenghu Zhou, [Is Reference Necessary in the Evaluation of NLG Systems? When and Where?](https://aclanthology.org/2024.naacl-long.474/)
7. Daniel Deutsch, Rotem Dror, Dan Roth, [On the Limitations of Reference-Free Evaluations of Generated Text](https://aclanthology.org/2022.emnlp-main.753/)
8. Dominic Petrak, Nafise Moosavi, Ye Tian, Nikolai Rozanov, Iryna Gurevych, [Learning From Free-Text Human Feedback – Collect New Datasets Or Extend Existing Ones?](https://aclanthology.org/2023.emnlp-main.1011/)

EMNLP'24 Papers
======
1. Jia-Chen Gu, Hao-Xiang Xu, Jun-Yu Ma, Pan Lu, Zhen-Hua Ling, Kai-Wei Chang, Nanyun Peng, [Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue](https://aclanthology.org/2024.emnlp-main.934/)
2. Yunxuan Li, Yibing Du, Jiageng Zhang, Le Hou, Peter Grabowski, Yeqing Li, Eugene Le, [Improving Multi-Agent Debate with Sparse Communication Topology](https://aclanthology.org/2024.findings-emnlp.427/)
3. Makesh Narsimhan Sreedhar, Traian Rebedea, Shaona Ghosh, Jiaqi Zeng, Christopher Parisien, [CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues](https://aclanthology.org/2024.findings-emnlp.713/)
4. Abhilasha Sancheti*, Haozhe An*, Rachel Rudinger, [On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models](https://aclanthology.org/2024.emnlp-main.29/)
5. James Liyuan Wang, Ran Li, Junfeng Yang, Chengzhi Mao, [RAFT: Realistic Attacks to Fool Text Detectors](https://aclanthology.org/2024.emnlp-main.939/)
6. Terra Blevins, Tomasz Limisiewicz, Suchin Gururangan, Margaret Li, Hila Gonen, Noah A. Smith, Luke Zettlemoyer, [Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models](https://aclanthology.org/2024.emnlp-main.604/)
7. Jacob Morrison, Noah A. Smith, Hannaneh Hajishirzi, Pang Wei Koh, Jesse Dodge, Pradeep Dasigi, [Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging](https://aclanthology.org/2024.findings-emnlp.915/)
8. Manya Wadhwa, Xinyu Zhao, Jessy Li, Greg Durrett, [Learning to Refine with Fine-Grained Natural Language Feedback](https://aclanthology.org/2024.findings-emnlp.716/)
9. Junehyung Kim, Sungjae Hwang, [All You Need is Attention: Lightweight Attention-based Data Augmentation for Text Classification](https://aclanthology.org/2024.findings-emnlp.752/)
10. Yang Ba, Michelle V. Mancenido, Rong Pan, [Fill In The Gaps: Model Calibration and Generalization with Synthetic Data](https://aclanthology.org/2024.emnlp-main.955/)
11. Rajiv Movva, Pang Wei Koh, Emma Pierson, [Annotation alignment: Comparing LLM and human annotations of conversational safety](https://aclanthology.org/2024.emnlp-main.511/)
12. Beiduo Chen, Xinpeng Wang, Siyao Peng, Robert Litschko, Anna Korhonen, Barbara Plank, [“Seeing the Big through the Small”: Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?](https://aclanthology.org/2024.findings-emnlp.842/)
13. Bingbing Wen, Bill Howe, Lucy Lu Wang, [Characterizing LLM Abstention Behavior in Science QA with Context Perturbations](https://aclanthology.org/2024.findings-emnlp.197/)
14. Yuqing Zhou, Ruixiang Tang, Ziyu Yao, Ziwei Zhu, [Navigating the Shortcut Maze: A Comprehensive Analysis of Shortcut Learning in Text Classification by Language Models](https://aclanthology.org/2024.findings-emnlp.146/)
15. Shangbin Feng, Taylor Sorensen, Yuhan Liu, Jillian Fisher, Chan Young Park, Yejin Choi, Yulia Tsvetkov, [Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration](https://aclanthology.org/2024.emnlp-main.240/)
16. Kyusik Kim, Hyeonseok Jeon, Jeongwoo Ryu, Bongwon Suh, [Will LLMs Sink or Swim? Exploring Decision-Making Under Pressure](https://aclanthology.org/2024.findings-emnlp.668/)
17. Adrian Cosma, Stefan Ruseti, Mihai Dascalu, Cornelia Caragea, [How Hard is this Test Set? NLI Characterization by Exploiting Training Dynamics](https://aclanthology.org/2024.emnlp-main.175/)
18. Lindia Tjuatja, Valerie Chen, Tongshuang Wu, Ameet Talwalkwar, Graham Neubig, [Do LLMs Exhibit Human-like Response Biases? A Case Study in Survey Design](https://aclanthology.org/2024.tacl-1.56/)
19. Jie Chen, Yupeng Zhang, Bingning Wang, Xin Zhao, Ji-Rong Wen, Weipeng Chen, [Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models](https://aclanthology.org/2024.findings-emnlp.873/)
20. Shramay Palta, Nishant Balepur, Peter A. Rankel, Sarah Wiegreffe, Marine Carpuat, Rachel Rudinger, [Plausibly Problematic Questions in Multiple-Choice Benchmarks for Commonsense Reasoning](https://aclanthology.org/2024.findings-emnlp.198/)
21. Abhishek Divekar, Greg Durrett, [SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation](https://aclanthology.org/2024.emnlp-main.1071/)
22. Jing Huang, Diyi Yang, Christopher Potts, [Demystifying Verbatim Memorization in Large Language Models](https://aclanthology.org/2024.emnlp-main.598/)
23. Thao Nguyen, Jeffrey Li, Sewoong Oh, Ludwig Schmidt, Jason E Weston, Luke Zettlemoyer, Xian Li, [Better Alignment with Instruction Back-and-Forth Translation](https://aclanthology.org/2024.findings-emnlp.777/)
24. Xinyi Xu, Zhaoxuan Wu, Rui Qiao, Arun Verma, Yao Shu, Jingtan Wang, Xinyuan Niu, Zhenfeng He, Jiangwei Chen, Zijian Zhou, Gregory Kang Ruey Lau, Hieu Dao, Lucas Agussurja, Rachael Hwee Ling Sim, Xiaoqiang Lin, Wenyang Hu, Zhongxiang Dai, Pang Wei Koh, Bryan Kian Hsiang Low, [Position Paper: Data-Centric AI in the Age of Large Language Models](https://aclanthology.org/2024.findings-emnlp.695/)
25. Johnathan Xie, Annie S Chen, Yoonho Lee, Eric Mitchell, Chelsea Finn, [Calibrating Language Models with Adaptive Temperature Scaling](https://aclanthology.org/2024.emnlp-main.1007/)
26. Fei Wang, Ninareh Mehrabi, Palash Goyal, Rahul Gupta, Kai-Wei Chang, Aram Galstyan, [Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models](https://aclanthology.org/2024.emnlp-main.461/)
27. Jared Moore, Tanvi Deshpande, Diyi Yang, [Are Large Language Models Consistent over Value-laden Questions?](https://aclanthology.org/2024.findings-emnlp.891/)
28. Isadora White, Sashrika Pandey, Michelle Pan, [Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication](https://aclanthology.org/2024.findings-emnlp.711/)
